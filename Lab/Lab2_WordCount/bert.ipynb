{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/word/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "os.environ['PYSPARK_PYTHON']='/home/hadoop/anaconda3/envs/word/bin/python'\n",
    "\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pyecharts.render import make_snapshot\n",
    "from snapshot_selenium import snapshot\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Pie, Bar, Funnel, Scatter\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "import torch\n",
    "from wordsegment import WordSegmenter\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hadoop/anaconda3/envs/word/bin/python\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "pythonpath = sys.executable\n",
    "print(pythonpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "# 配置spark\n",
    "  \n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"lab2\")\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "sc.stop()\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# 读取停用词文件\n",
    "stopWords_filePath = \"src/stop_words.txt\"\n",
    "with open(stopWords_filePath, \"r\", encoding=\"utf-8\") as file:\n",
    "    stopWords = [line.strip() for line in file.readlines()]\n",
    "\n",
    "# 读取文本内容并进行分词\n",
    "data_filePath = \"src/data.txt\"\n",
    "dataRdd = sc.textFile(data_filePath)\n",
    "text = dataRdd.reduce(lambda a, b: a + \" \" + b)\n",
    "lines_list = text.splitlines()\n",
    "\n",
    "#print(lines_list[:1])\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#words_list = jieba.lcut(text)\n",
    "\n",
    "#bert分词\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ckiplab/albert-base-chinese-ws\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ckiplab/albert-base-chinese-ws\")\n",
    "ws = WordSegmenter(model=model,tokenizer=tokenizer,device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "words_list = ws.segment(lines_list)\n",
    "print(len(ws.segment(lines_list)))\n",
    "\n",
    "print(words_list[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# 扁平化 words_list\n",
    "flat_words_list = list(itertools.chain(*words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建RDD并进行词频统计\n",
    "#wordsRdd = sc.parallelize(words_list)\n",
    "wordsRdd = sc.parallelize(flat_words_list)\n",
    "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "#print(wordsRdd[:1])\n",
    "resRdd = wordsRdd.filter(lambda word: word not in stopWords) \\\n",
    "    .filter(lambda word: len(word) > 1) \\\n",
    "        .map(lambda word: (word, 1)) \\\n",
    "            .reduceByKey(lambda a, b: a + b) \\\n",
    "                .sortBy(lambda x: x[1], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置中文字体\n",
    "font_name = \"SimHei\"\n",
    "plt.rcParams['font.family']= font_name # 指定字体，实际上相当于修改 matplotlibrc 文件　只不过这样做是暂时的　下次失效\n",
    "plt.rcParams['axes.unicode_minus']=False # 正确显示负号，防止变成方框\n",
    "\n",
    "print(type(resRdd))\n",
    "print(words_list[:])\n",
    "# 绘制词频直方图，展示前20个词语的词频分布\n",
    "top20 = resRdd.take(20)\n",
    "words, frequencies = zip(*top20)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(y=list(words), x=list(frequencies))\n",
    "plt.title(\"词频排名前二十\", fontsize=15)\n",
    "plt.xlabel(\"频率\", fontsize=15)\n",
    "plt.ylabel(\"词语\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词云生成\n",
    "top50 = resRdd.take(50)\n",
    "wc = WordCloud(font_path=\"/home/hadoop/anaconda3/envs/word/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/ttf/SimHei.ttf\",\n",
    "               background_color=\"white\", \n",
    "               width=1920, height=1080, \n",
    "               max_words=2000, \n",
    "               margin=5)\n",
    "wc.generate_from_frequencies(dict(top50))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将RDD转换为Dic，并截取指定长度topK\n",
    "def rdd2dic(resRdd,topK):\n",
    "        \"\"\"\n",
    "        将RDD转换为Dic，并截取指定长度topK\n",
    "        :param resRdd: 词频统计降序排序结果RDD\n",
    "        :param topK: 截取的指定长度\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 提示：SparkRdd有函数可直接转换\n",
    "        resDic = resRdd.collectAsMap()\n",
    "        # 截取字典前K个\n",
    "        K = 0\n",
    "        wordDicK = {}\n",
    "        for key, value in resDic.items():\n",
    "            # 完成循环截取字典\n",
    "            if K >= topK:\n",
    "                break\n",
    "            wordDicK[key] = value\n",
    "            K += 1\n",
    "        return wordDicK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVAPATH = '/home/hadoop/ex2/Lab2_WordCount/results_bert/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成词云\n",
    "wwDic = rdd2dic(resRdd,50)\n",
    "wc = WordCloud(font_path='/home/hadoop/anaconda3/envs/word/lib/python3.9/site-packages/matplotlib/mpl-data/fonts/ttf/SimHei.ttf',\n",
    "                       background_color='white',\n",
    "                       max_words=2000,\n",
    "                       width=1920, height=1080,\n",
    "                       margin=5)\n",
    "wc.generate_from_frequencies(wwDic)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "if not os.path.exists(SAVAPATH):\n",
    "            os.makedirs(SAVAPATH)\n",
    "wc.to_file(os.path.join(SAVAPATH, '词云可视化.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前需要安装“WenQuanYi Zen Hei”字体，命令：sudo apt-get install fonts-wqy-zenhei（ubuntu）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 饼图可视化\n",
    "\n",
    "pieDic = rdd2dic(resRdd,10)\n",
    "key_list = pieDic.keys()      # wordDic所有key组成list\n",
    "value_list= pieDic.values()   # wordDic所有value组成list\n",
    "def pie_position() -> Pie:\n",
    "    c = (\n",
    "        Pie()\n",
    "            .add\n",
    "            (\n",
    "            \"\",\n",
    "            [list(z) for z in zip(key_list, value_list)], # dic -> list\n",
    "            center=[\"35%\", \"50%\"],\n",
    "            )\n",
    "            .set_global_opts\n",
    "            (\n",
    "            title_opts=opts.TitleOpts(\n",
    "                title='饼图可视化',\n",
    "                title_textstyle_opts=opts.TextStyleOpts(font_size=18, font_family=\"WenQuanYi Zen Hei\", color=\"#333\")\n",
    "                ), # 设置标题\n",
    "            legend_opts=opts.LegendOpts(\n",
    "                pos_left=\"15%\",\n",
    "                textstyle_opts=opts.TextStyleOpts(font_size=12, color=\"#666\")  # 设置图例字体\n",
    "                ),\n",
    "            )\n",
    "            .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}\"))\n",
    "    )\n",
    "    return c\n",
    "\n",
    "image_path = SAVAPATH + '饼图可视化.png'\n",
    "\n",
    "# 保存结果\n",
    "make_snapshot(snapshot, pie_position().render(), image_path)\n",
    "img = mpimg.imread(image_path)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 柱状图可视化\n",
    "Dic = rdd2dic(resRdd,15)\n",
    "\n",
    "key_list = Dic.keys()      # wordDic所有key组成list\n",
    "value_list= Dic.values()   # wordDic所有value组成list\n",
    "def bar_position() -> Bar:\n",
    "    bar = (\n",
    "        Bar()\n",
    "            .add_xaxis(list(key_list))\n",
    "            .add_yaxis(\"次数\", list(value_list))\n",
    "            .set_global_opts\n",
    "            (\n",
    "            title_opts=opts.TitleOpts(title='柱状图可视化'), # 设置标题\n",
    "            legend_opts=opts.LegendOpts(pos_left=\"15%\"),\n",
    "            )\n",
    "            .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}\"))\n",
    "        )\n",
    "    return bar\n",
    "# 保存结果\n",
    "\n",
    "image_path = SAVAPATH + '柱状图可视化.png'\n",
    "make_snapshot(snapshot, bar_position().render(), image_path)\n",
    "\n",
    "img = mpimg.imread(image_path)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 漏斗图可视化\n",
    "Dic = rdd2dic(resRdd,15)\n",
    "\n",
    "key_list = list(Dic.keys())      # wordDic所有key组成list\n",
    "value_list= list(Dic.values())   # wordDic所有value组成list\n",
    "data = [[key_list[i],value_list[i]]for i in range(len(key_list))]\n",
    "def funnel_position() -> Funnel:\n",
    "    funnel = (\n",
    "        Funnel()\n",
    "            .add(\n",
    "                series_name=\"\",\n",
    "                data_pair=data,\n",
    "                gap=2,\n",
    "                tooltip_opts=opts.TooltipOpts(trigger=\"item\", formatter=\"{a} <br/>{b} : {c}%\"),\n",
    "                label_opts=opts.LabelOpts(is_show=True, position=\"inside\"),\n",
    "                itemstyle_opts=opts.ItemStyleOpts(border_color=\"#fff\", border_width=1),\n",
    "            )\n",
    "            .set_global_opts(title_opts=opts.TitleOpts(title=\"漏斗图\"))\n",
    "    )\n",
    "    return funnel\n",
    "# 保存结果\n",
    "\n",
    "image_path = SAVAPATH + '漏斗图可视化.png'\n",
    "make_snapshot(snapshot, funnel_position().render(), image_path)\n",
    "\n",
    "img = mpimg.imread(image_path)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 散点图可视化\n",
    "\n",
    "Dic = rdd2dic(resRdd,15)\n",
    "\n",
    "key_list = list(Dic.keys())      # wordDic所有key组成list\n",
    "value_list= list(Dic.values())   # wordDic所有value组成list\n",
    "def scatter_position() -> Funnel:\n",
    "    scatter = (\n",
    "        Scatter()\n",
    "            .add_xaxis(key_list)\n",
    "            .add_yaxis(\"次数\", value_list)\n",
    "            .set_global_opts(\n",
    "                title_opts=opts.TitleOpts(title=\"Scatter-VisualMap(Size)\"),\n",
    "                visualmap_opts=opts.VisualMapOpts(type_=\"size\", max_=150, min_=20),\n",
    "        )\n",
    "    )\n",
    "    return scatter\n",
    "# 保存结果\n",
    "image_path = SAVAPATH + '散点图可视化.png'\n",
    "make_snapshot(snapshot, scatter_position().render(), image_path)\n",
    "\n",
    "img = mpimg.imread(image_path)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "word",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
