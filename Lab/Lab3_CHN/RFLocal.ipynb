{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark 配置成功\n",
      "-----加载训练数据-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----训练数据加载成功-----\n",
      "-----加载测试数据-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----测试数据加载成功-----\n",
      "-----开始训练随机森林模型-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林模型准确率: 0.7387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林模型已保存至：hdfs:///chn/model/RandomForest\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import os\n",
    "\n",
    "# 配置 SparkConf 使用 LOCAL 模式\n",
    "conf = SparkConf() \\\n",
    "    .setAppName(\"CHN_LOCAL_RandomForest\") \\\n",
    "    .setMaster(\"local[*]\") \\\n",
    "    .set(\"spark.executor.memory\", \"8g\") \\\n",
    "    .set(\"spark.driver.memory\", \"8g\") \\\n",
    "    .set(\"spark.executor.cores\", \"4\") \\\n",
    "    .set(\"spark.driver.cores\", \"4\")\n",
    "\n",
    "# 初始化 SparkSession\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "print(\"Spark 配置成功\")\n",
    "\n",
    "TRAIN_PATH = \"/chn/train.csv\"\n",
    "TEST_PATH = \"/chn/test.csv\"\n",
    "MODEL_SAVE_DIR = \"hdfs:///chn/model\"\n",
    "\n",
    "# 加载并查看训练数据的前几行\n",
    "print(\"-----加载训练数据-----\")\n",
    "train_rdd = spark.sparkContext.textFile(TRAIN_PATH)\n",
    "train_data = train_rdd.map(lambda line: Row(\n",
    "    label=float(line.split(\",\")[-1]),\n",
    "    features=Vectors.dense([float(x) for x in line.split(\",\")[:-1]])\n",
    ")).toDF()\n",
    "\n",
    "# 随机采样训练数据\n",
    "sampled_train_data = train_data.sample(withReplacement=False, fraction=0.2, seed=42)\n",
    "\n",
    "# 将特征转换为单个向量列\n",
    "vector_assembler = VectorAssembler(inputCols=[\"features\"], outputCol=\"features_vec\")\n",
    "train_data = vector_assembler.transform(sampled_train_data).select(\"features_vec\", \"label\")\n",
    "print(\"-----训练数据加载成功-----\")\n",
    "\n",
    "# 加载并查看测试数据的前几行\n",
    "print(\"-----加载测试数据-----\")\n",
    "test_rdd = spark.sparkContext.textFile(TEST_PATH)\n",
    "test_data = test_rdd.map(lambda line: Row(\n",
    "    label=float(line.split(\",\")[-1]),\n",
    "    features=Vectors.dense([float(x) for x in line.split(\",\")[:-1]])\n",
    ")).toDF()\n",
    "\n",
    "test_data = vector_assembler.transform(test_data).select(\"features_vec\", \"label\")\n",
    "print(\"-----测试数据加载成功-----\")\n",
    "\n",
    "# 定义评估器，使用多分类的准确率评估\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# 设置随机森林模型，直接指定基础参数\n",
    "rf = RandomForestClassifier(featuresCol=\"features_vec\", labelCol=\"label\", numTrees=20, maxDepth=10)\n",
    "\n",
    "print(\"-----开始训练随机森林模型-----\")\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# 在测试数据上评估模型\n",
    "predictions = rf_model.transform(test_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"随机森林模型准确率: {accuracy:.4f}\")\n",
    "\n",
    "# 保存模型\n",
    "best_model_save_path = os.path.join(MODEL_SAVE_DIR, \"RandomForest\")\n",
    "rf_model.save(best_model_save_path)\n",
    "print(f\"随机森林模型已保存至：{best_model_save_path}\")\n",
    "\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_lab_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
