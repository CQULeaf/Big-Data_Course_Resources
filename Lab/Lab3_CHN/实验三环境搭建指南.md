# 搭建实验三运行环境

- [搭建实验三运行环境](#搭建实验三运行环境)
  - [实验目的](#实验目的)
  - [下载`OpenCV-Python`库](#下载opencv-python库)
    - [第一步：选择合适的镜像源和文件](#第一步选择合适的镜像源和文件)
    - [第二步：在之前创建的 `conda` 环境中直接下载对应库](#第二步在之前创建的-conda-环境中直接下载对应库)
    - [第三步：验证是否安装成功](#第三步验证是否安装成功)
  - [解决使用分布式系统时的小问题](#解决使用分布式系统时的小问题)
    - [同步所有节点的 Python 环境](#同步所有节点的-python-环境)

## 实验目的

在前面两次实验的基础上加以补充，来完成本次实验，主要有：

1. 下载与使用`OpenCV-Python`库
2. 解决使用分布式时所遇问题

## 下载`OpenCV-Python`库

### 第一步：选择合适的镜像源和文件

> 这里提供[清华镜像源](https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/opencv-python/)，可以在其中选择合适镜像文件

因为我们的系统是**Ubuntu 22.04 LTS**且**Python版本为3.10**，对应选择***opencv_python-4.5.4.60-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl***。cp310对应Python 3.10，注意这个即可，同时下面下载安装时会使用 `4.5.4.60` 这个版本号，如果你选择了其它，请注意更改对应下载命令。

### 第二步：在之前创建的 `conda` 环境中直接下载对应库

```bash
conda activate big_data_lab_env
pip install opencv-python==4.5.4.60 --index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### 第三步：验证是否安装成功

![test OpenCV-Python install](images/opencv-test.png)

如果如上显示，则证明成功！

## 解决使用分布式系统时的小问题

> 注意：该部分仍然是建立在原教程之上，详见[实验三：中文手写数字分类](https://github.com/Wanghui-Huang/CQU_bigdata/blob/master/Experiment/Ex3/Ex3_CHN/ex3.md)

### 同步所有节点的 Python 环境

> 因为 Spark 的任务需要在每个节点的独立 Python 环境中执行，因此所有节点都应该拥有统一的 Python 环境。而我们之前使用的 Anaconda 无疑极大方便了我们这一需求！

1. 在主节点上导出 `conda` 环境（主做）

    ```bash
    conda activate big_data_lab_env
    conda env export > big_data_lab_env.yml
    ```

2. 将导出的文件分发到从节点（主做）

    ```bash
    scp big_data_lab_env.yml ecs-user@yexuhang:/home/ecs-user/
    ```

3. 在从节点上创建相同的 `conda` 环境（从做）

    ```bash
    conda env create -f /home/ecs-user/big_data_lab_env.yml
    ```

4. 验证从节点上相应的环境是否正常安装（从做，选做）

    ```bash
    conda activate big_data_lab_env
    conda list
    ```

5. 配置 `spark-env.sh` 文件（都做）

    首先，如果你不确定自己目前 `conda` 的 Python 路径，你可以输入如下命令进行查找：

    ```bash
    conda activate big_data_lab_env
    which python
    ```

    你应该会得到如同 `/home/ecs-user/anaconda3/envs/big_data_lab_env/bin/python` 这样的输出。

    然后，进行配置文件的修改：

    ```bash
    vim /usr/local/spark/conf/spark-env.sh
    ```

    在文件中任意位置加入下面这一行

    ```bash
    export PYSPARK_PYTHON=/home/ecs-user/anaconda3/envs/big_data_lab_env/bin/python
    source /home/ecs-user/anaconda3/bin/activate big_data_lab_env
    ```

    请记得重启 Spark 集群以应用新的环境设置。

